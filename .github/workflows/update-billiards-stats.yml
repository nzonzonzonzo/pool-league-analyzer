name: Update Billiards Stats

on:
  schedule:
    - cron: '0 10 * * 4'  # Run every Thursday at 10 AM UTC
  workflow_dispatch:      # Allow manual triggering

jobs:
  update-stats:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
        with:
          fetch-depth: 0  # Fetch all history for all branches and tags
      
      - name: Set up Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'
          
      - name: Install dependencies
        run: npm install
      
      - name: Create data directories if they don't exist
        run: mkdir -p public/data/archives
      
      - name: Archive current stats file if it exists
        run: |
          if [ -f public/data/team_stats.json ]; then
            # Create a timestamp for the archive filename
            TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
            # Copy the current file to the archive with the timestamp
            cp public/data/team_stats.json public/data/archives/team_stats_${TIMESTAMP}.json
            echo "Archived current stats to public/data/archives/team_stats_${TIMESTAMP}.json"
          else
            echo "No existing stats file to archive"
          fi
      
      - name: Run scraper
        run: |
          # Create a temporary copy of the scraper with the secret cookie
          cat > temp_scraper.js << 'EOL'
          const { scrapeAndUpdateStats } = require('./scraper.js');
          
          // Run the scraper with the correct path and secret cookie
          scrapeAndUpdateStats('public/data/team_stats.json', '${{ secrets.BILLIARDS_COOKIE }}')
            .then(data => {
              console.log(`Scraper completed successfully. Processed ${data.length} player records.`);
              
              // Validation to ensure we don't save empty data
              if (data.length < 50) {
                console.warn(`Warning: Scraped data appears small. Only found ${data.length} players.`);
              }
            })
            .catch(err => { 
              console.error('Scraper failed:', err); 
              process.exit(1); 
            });
          EOL
          
          # Run the temporary script
          node temp_scraper.js
          
          # Remove the temporary script that contains the secret
          rm temp_scraper.js
      
      - name: Commit and push changes
        uses: EndBug/add-and-commit@v9
        with:
          add: 'public/data/'
          message: 'Auto-update billiards stats on $(date +"%Y-%m-%d")'
          push: true
          default_author: github_actions
